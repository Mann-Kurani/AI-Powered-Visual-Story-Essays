{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"isAy5fPJ2JV3","outputId":"85007da0-02bb-499a-f2e8-a6ed33b2d9fe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","import shutil\n","import os\n","import ast"],"metadata":{"id":"8UaEBNam2-2R"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Getting the required files from the Drive"],"metadata":{"id":"oXttl8oTHMkA"}},{"cell_type":"code","source":["# Define source and destination paths\n","drive_folder = \"/content/drive/MyDrive/Projects/Stable-Diffusion-From-Scratch/sd\"  # Replace with your folder name\n","destination_folder = \"/content/\"  # Current directory in Colab\n","\n","# Ensure destination folder exists\n","os.makedirs(destination_folder, exist_ok=True)\n","\n","# Copy all files from the Drive folder to the current directory\n","for filename in os.listdir(drive_folder):\n","    src = os.path.join(drive_folder, filename)\n","    dst = os.path.join(destination_folder, filename)\n","    shutil.copy(src, dst)\n","\n","print(\"Files copied successfully!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"njCeUM9n22nm","outputId":"8de57c67-e8fe-44f3-e83a-f4fa573becfc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Files copied successfully!\n"]}]},{"cell_type":"markdown","source":["## Downloading required models and libraries"],"metadata":{"id":"0o7kAxe4HSZQ"}},{"cell_type":"code","source":["%run -i '/content/init.py'"],"metadata":{"id":"8njRfFoQ08dz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from auth import get_gemini_api_key\n","API_KEY = get_gemini_api_key()"],"metadata":{"id":"Q6e4cLOC85Sl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Loading the Stable Diffusion model"],"metadata":{"id":"uKqVWLTxHask"}},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"x_dhQfFYXoPu","colab":{"base_uri":"https://localhost:8080/"},"outputId":"80bbe4e2-f451-464d-a4cd-a2e1d78137a2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}],"source":["import model_loader # personal python script\n","import pipeline # personal python script\n","from PIL import Image\n","from pathlib import Path\n","from transformers import CLIPTokenizer\n","import torch\n","import matplotlib.pyplot as plt\n","\n","DEVICE = \"cuda\"\n","\n","ALLOW_CUDA = True\n","ALLOW_MPS = False\n","\n","if torch.cuda.is_available() and ALLOW_CUDA:\n","    DEVICE = \"cuda\"\n","elif (torch.has_mps or torch.backends.mps.is_available()) and ALLOW_MPS:\n","    DEVICE = \"mps\"\n","print(f\"Using device: {DEVICE}\")\n","\n","tokenizer = CLIPTokenizer(\"/content/data/vocab.json\", merges_file=\"/content/data/merges.txt\")\n","model_file = \"/content/data/v1-5-pruned-emaonly.ckpt\"\n","models = model_loader.preload_models_from_standard_weights(model_file, DEVICE)"]},{"cell_type":"markdown","source":["## Loading the pdf"],"metadata":{"id":"SjJBEEjoHfSd"}},{"cell_type":"code","source":["from langchain_community.document_loaders import PyPDFLoader\n","\n","loader = PyPDFLoader(\"/content/Frankenstein_Project_Gutenberg_Small.pdf\")\n","pages = loader.load_and_split()\n","# pages"],"metadata":{"id":"xw-nQO6hoR6s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pg = pages[0].page_content"],"metadata":{"id":"LeMW3phEo3Do"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Prompting and fetching the response from Gemini"],"metadata":{"id":"rn3mHItwHiW3"}},{"cell_type":"code","source":["content = f\"\"\"The narrator is Frankenstein FYI\n","I want to make a story essay with the given context story. Only give me 5 points that summarizes it from third person pronouns and nouns (Use character names), make sure the story has a good flow and give the output in the form of a python list.\n","context: '{pg}' \"\"\""],"metadata":{"id":"FRjK2RMb9cXz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google import genai\n","\n","client = genai.Client(api_key=API_KEY)\n","response = client.models.generate_content(\n","    model=\"gemini-2.0-flash\", contents=content\n",")\n","response_text = response.text"],"metadata":{"id":"yS3lozic9UPs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["clean_text = response_text.replace(\"\\n\", \"\").replace(\"```\", \"\").replace(\"python\", \"\").strip()"],"metadata":{"id":"2zq3yx9T-V95"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convert string to dictionary\n","story_summary = ast.literal_eval(clean_text)"],"metadata":{"id":"-wqDE01lB9TV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Setting the hyperparameters of the Stable Diffusion model"],"metadata":{"id":"-sTDdhOrHpsm"}},{"cell_type":"code","source":["uncond_prompt = \"blurry, low quality, distorted\"  # Also known as negative prompt\n","do_cfg = True\n","cfg_scale = 10  # min: 1, max: 14. Controls the strength of guidance toward the prompt\n","prompts = story_summary\n","input_image = None\n","strength = 0.9\n","sampler = \"ddpm\"\n","num_inference_steps = 50\n","seed = None"],"metadata":{"id":"HWRulpHruI5s"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Running the inference and saving the images"],"metadata":{"id":"lyC9iYDKH0WU"}},{"cell_type":"code","source":["for i, prompt in enumerate(prompts, start=1):\n","\n","  output_image = pipeline.generate(\n","      prompt=prompt,\n","      uncond_prompt=uncond_prompt,\n","      input_image=input_image,\n","      strength=strength,\n","      do_cfg=do_cfg,\n","      cfg_scale=cfg_scale,\n","      sampler_name=sampler,\n","      n_inference_steps=num_inference_steps,\n","      seed=seed,\n","      models=models,\n","      device=DEVICE,\n","      idle_device=\"cpu\",\n","      tokenizer=tokenizer,\n","  )\n","  # Display and save the image with title using matplotlib\n","  plt.figure(figsize=(8, 8))  # Adjust figure size if needed\n","  plt.imshow(output_image)\n","  plt.title(prompt, fontsize=12, wrap=True)  # Add title\n","  plt.axis(\"off\")\n","  # plt.show()\n","\n","    # Save the image inside the 'images' folder\n","  image_path = os.path.join(\"images\", f\"img{i}.jpg\")\n","  plt.savefig(image_path, bbox_inches=\"tight\", pad_inches=0.2)  # Save with padding\n","  plt.close()  # Close figure to free memory\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VN48BzRktU2r","outputId":"7ec9d646-8c7d-43ac-ed77-b08dca3c331c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 50/50 [00:30<00:00,  1.65it/s]\n","100%|██████████| 50/50 [00:31<00:00,  1.60it/s]\n","100%|██████████| 50/50 [00:30<00:00,  1.66it/s]\n","100%|██████████| 50/50 [00:30<00:00,  1.62it/s]\n","100%|██████████| 50/50 [00:30<00:00,  1.65it/s]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"NXyOdBnvtUy9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ZmMKWthdtUWX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"IcGAQ8qCrAW5"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":0}